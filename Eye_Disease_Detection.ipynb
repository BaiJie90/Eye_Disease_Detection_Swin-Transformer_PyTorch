{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQiaqPgT6uRc"
      },
      "source": [
        "Title: Eye Disease Detection Swin-Transformer PyTorch \\\n",
        "Author: Bai Jie Cao, Maxine Olexa Phoa, Omole Olakunle A. \\\n",
        "Date created: 2023/10/13 \\\n",
        "Description: Image classification using Swin Transformer. \\\n",
        "Accelerator: GPU\n",
        "\n",
        "This model implements [Swin Transformer: Hierarchical Vision Transformer using Shifted Windows](https://arxiv.org/abs/2103.14030)\n",
        "by Liu et al. for image classification.\n",
        "\n",
        "Swin Transformer (**S**hifted **Win**dow Transformer) can serve as a general-purpose backbone\n",
        "for computer vision. Swin Transformer is a hierarchical Transformer whose\n",
        "representations are computed with _shifted windows_. The shifted window scheme\n",
        "brings greater efficiency by limiting self-attention computation to\n",
        "non-overlapping local windows while also allowing for cross-window connections.\n",
        "This architecture has the flexibility to model information at various scales and has\n",
        "a linear computational complexity with respect to image size.\n",
        "\n",
        "Code taken from [Flower Classification Swin Transformer Pytorch | Kaggle](https://www.kaggle.com/code/hamedghorbani/flower-classification-swin-transformer-pytorch/notebook) and adapted for personal use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJa8ysyp77gT"
      },
      "source": [
        "## 1 Initial Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Load needed packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is important to note that some of these packages/libraries are version dependent on which system you are running this notebook on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ss9SRB6H_1uv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "from torch.utils.data import Dataset , DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.models.swin_transformer import *\n",
        "from torchvision.utils import make_grid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 GPU setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use the dedicated GPU if available otherwise use CPU for the computations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fCpRm1W6csH",
        "outputId": "74d468e0-c14a-4bf2-f39e-3e30cb713460"
      },
      "outputs": [],
      "source": [
        "# Setting device on GPU if available, else CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "print()\n",
        "\n",
        "# Additional Info when using cuda\n",
        "if device.type == 'cuda':\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "    print('Memory Usage:')\n",
        "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7iqEMEs8EOQ"
      },
      "source": [
        "## 2 Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0b_xDkd8LAm"
      },
      "source": [
        "### 2.1 Loading Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the dataset into a panda `DataFrame`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgoStaqtAh9m"
      },
      "outputs": [],
      "source": [
        "path = \"./data/\"\n",
        "\n",
        "data = {\"imgpath\": [] , \"labels\": [] }\n",
        "\n",
        "category = os.listdir(path)\n",
        "for folder in category:\n",
        "    folderpath = os.path.join(path , folder)\n",
        "    filelist = os.listdir(folderpath)\n",
        "    for file in filelist:\n",
        "        fpath = os.path.join(folderpath, file)\n",
        "        data[\"imgpath\"].append(fpath)\n",
        "        data[\"labels\"].append(folder)\n",
        "\n",
        "df = pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Convert the labels to numbers for classification and print out the `DataFrame`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IbFxSOAE4re",
        "outputId": "b2ecbe2f-860c-45d8-9cf6-78f6829afe34"
      },
      "outputs": [],
      "source": [
        "# Convert labels to numbers\n",
        "lb = LabelEncoder()\n",
        "df['encoded_labels'] = lb.fit_transform(df['labels'])\n",
        "\n",
        "print(\"-------------Fetch files into a data frame-----------\")\n",
        "print(df)\n",
        "print(\"-------------Path to an image file------------------\")\n",
        "print(df.loc[175]['imgpath'])\n",
        "print(\"-----------Number of images per category--------------\")\n",
        "print(df.labels.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCUvcKYQ8UZj"
      },
      "source": [
        "### 2.2 Split Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Split the dataset into training and validation/testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_i5LCZTC4MZI",
        "outputId": "3160eeec-9349-47cf-d407-a42a74e36cc5"
      },
      "outputs": [],
      "source": [
        "train_df, valid_df = train_test_split(df,  train_size= 0.80 , shuffle=True, random_state=124)\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "valid_df = valid_df.reset_index(drop=True)\n",
        "\n",
        "print(\"#############Train Split###################\")\n",
        "print(train_df.head(5))\n",
        "print(train_df.shape)\n",
        "print(\"#############Test Split###################\")\n",
        "print(valid_df.head(5))\n",
        "print(valid_df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQWFsVC98bCX"
      },
      "source": [
        "### 2.3 Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Perform needed data augmentations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFEi1Sd76dZj"
      },
      "outputs": [],
      "source": [
        "image_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n",
        "        transforms.RandomRotation(degrees=15),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.CenterCrop(size=224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ]),\n",
        "    'valid': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ]),\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaCkBi498tzB"
      },
      "source": [
        "### 2.4 Train and Test Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Declare the `eye_Dataset` class to be used to get the images and do the needed data augmentations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4K_UUplFv_b",
        "outputId": "8a035517-d50b-4489-e842-827ee131507a"
      },
      "outputs": [],
      "source": [
        "class eye_Dataset(Dataset):\n",
        "    def __init__(self, img_data,transform=None):\n",
        "        self.transform = transform\n",
        "        self.img_data = img_data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_name = self.img_data.loc[index]['imgpath']\n",
        "        imge = Image.open(img_name)\n",
        "        image = imge.resize((224,224))\n",
        "        label = torch.tensor(self.img_data.loc[index]['encoded_labels'])\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "training_data = eye_Dataset(train_df, image_transforms['train'])\n",
        "validatin_data = eye_Dataset(valid_df, image_transforms['valid'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.5 Train and Test Dataset properties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwg0GOMWFzZd",
        "outputId": "cc19f998-c5c0-4dd8-81a8-3e05dc8ee670"
      },
      "outputs": [],
      "source": [
        "train_batch_size = 64\n",
        "val_batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=train_batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(validatin_data, batch_size=val_batch_size , shuffle=True)\n",
        "\n",
        "print(\">> Number of Train Data : {} -- Batch Size : {} -- Number of Batch : {} \".format(len(train_dataloader.dataset) , train_batch_size , len(train_dataloader)))\n",
        "print(\">> Number of Validiation Data : {} -- Batch Size : {} -- Number of Batch : {} \".format(len(test_dataloader.dataset) , val_batch_size , len(test_dataloader)))\n",
        "onebatch = iter(train_dataloader)\n",
        "train_features, train_labels = next(onebatch)\n",
        "print(\"----------Batch Shape--------\")\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(\"----------Labels Shape--------\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "UDKpgxQoF0jK",
        "outputId": "a8cccf76-439a-40e5-94b1-cadbf2baa4de"
      },
      "outputs": [],
      "source": [
        "mean = np.array([0.5, 0.5, 0.5])\n",
        "std = np.array([0.25, 0.25, 0.25])\n",
        "def imeshow(inp):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0,2)\n",
        "    plt.imshow(inp)\n",
        "    plt.show()\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(test_dataloader))\n",
        "\n",
        "# Make a grid from batch\n",
        "out = make_grid(inputs)\n",
        "imeshow(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtBRIXhT85-u"
      },
      "source": [
        "## 3 Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgWlZbdM_yld"
      },
      "source": [
        "### 3.1 Model Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the pre-trained model or download the needed weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSxS_I_QF7l9",
        "outputId": "c441baa0-495a-4f9c-8468-8be6c98b215a"
      },
      "outputs": [],
      "source": [
        "model = swin_t(weights=True)\n",
        "for param in model.parameters(): #freeze model\n",
        "    param.requires_grad = False\n",
        "\n",
        "n_inputs = model.head.in_features\n",
        "\n",
        "model.head = nn.Sequential(\n",
        "    nn.Linear(n_inputs, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(512, 4) #,5 for classes\n",
        ")\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion = criterion.to(device)\n",
        "optimizer = optim.AdamW(model.head.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acDXbayO9IcO"
      },
      "source": [
        "### 3.2 Training and Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Declare code blocks used for training and testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOfsk7muGKwE"
      },
      "outputs": [],
      "source": [
        "def train_model(model, optimizer, criterion , data_loader, device):\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "\n",
        "    for i, data in enumerate(data_loader):\n",
        "        inputs , labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        labels = labels.to(torch.int64)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    avg_train_loss = running_loss / len(data_loader.dataset)\n",
        "    avg_train_acc = ( correct / len(data_loader.dataset) ) * 100\n",
        "    print(\">>> Train loss {} ---- Accuracy Train {} \".format(avg_train_loss, avg_train_acc))\n",
        "\n",
        "    return avg_train_loss , avg_train_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWgZbvkVGKMs"
      },
      "outputs": [],
      "source": [
        "def test_model(model, criterion , data_loader, device):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    all_labels = []\n",
        "    all_predicted = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(data_loader):\n",
        "            inputs , labels = data\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            labels = labels.to(torch.int64)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predicted.extend(predicted.cpu().numpy())\n",
        "\n",
        "        avg_val_acc = ( correct / len(data_loader.dataset) ) * 100\n",
        "        avg_val_loss = val_loss / len(data_loader.dataset)\n",
        "\n",
        "        f1 = f1_score(all_labels, all_predicted, average='weighted') * 100\n",
        "\n",
        "        print(\">>> Validation loss {} ---- Validation Accuracy {} ---- F1 Score {}\".format(avg_val_loss, avg_val_acc, f1))\n",
        "\n",
        "    return avg_val_loss , avg_val_acc, f1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ed74Hjfd9Ye7"
      },
      "source": [
        "### 3.3 Run the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJ5adLJ8GOY7",
        "outputId": "5e20f4c8-a06a-47a4-c46d-d61eed07cb13"
      },
      "outputs": [],
      "source": [
        "num_epochs = 200\n",
        "history = {  \"train_loss\" : [] ,  \"train_acc\" : [] ,  \"val_loss\" : [] ,  \"val_acc\" : [], \"val_f1\": []}\n",
        "\n",
        "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "    print(\"------------------ Training Epoch {} ------------------\".format(epoch+1))\n",
        "    T_loss , T_acc = train_model(model , optimizer , criterion, train_dataloader , device)\n",
        "    V_loss , V_acc, V_f1 = test_model(model , criterion , test_dataloader, device)\n",
        "\n",
        "    history[\"train_loss\"].append(T_loss)\n",
        "    history[\"train_acc\"].append(T_acc)\n",
        "    history[\"val_loss\"].append(V_loss)\n",
        "    history[\"val_acc\"].append(V_acc)\n",
        "    history[\"val_f1\"].append(V_f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.4 Plot essential metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guAxhjGGGT0b"
      },
      "outputs": [],
      "source": [
        "# Define needed variables\n",
        "tr_acc = history[\"train_acc\"]\n",
        "tr_loss = history[\"train_loss\"]\n",
        "val_acc = history[\"val_acc\"]\n",
        "val_loss = history[\"val_loss\"]\n",
        "\n",
        "index_loss = np.argmin(val_loss)\n",
        "val_lowest = val_loss[index_loss]\n",
        "index_acc = np.argmax(val_acc)\n",
        "acc_highest = val_acc[index_acc]\n",
        "Epochs = [i+1 for i in range(len(tr_acc))]\n",
        "loss_label = f'best epoch= {str(index_loss + 1)}'\n",
        "acc_label = f'best epoch= {str(index_acc + 1)}'\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize= (20, 8))\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n",
        "plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n",
        "plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n",
        "plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n",
        "plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMKjtFK9WR33"
      },
      "source": [
        "## 4 Evaluation Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Brxr1DKCb7nu"
      },
      "outputs": [],
      "source": [
        "def evaluate_classification_metrics(all_labels, all_predicted):\n",
        "    accuracy = accuracy_score(all_labels, all_predicted)\n",
        "    precision = precision_score(all_labels, all_predicted, average='weighted')\n",
        "    recall = recall_score(all_labels, all_predicted, average='weighted')\n",
        "    f1 = f1_score(all_labels, all_predicted, average='weighted')\n",
        "\n",
        "    cm = confusion_matrix(all_labels, all_predicted)\n",
        "    class_accuracies = cm.diagonal() / cm.sum(axis=1)\n",
        "\n",
        "    return accuracy, precision, recall, f1, class_accuracies\n",
        "\n",
        "def display_sample_image(model, data_loader, device, label_encoder):\n",
        "    model.eval()\n",
        "    sample_index = np.random.randint(len(data_loader.dataset))\n",
        "    sample_image, sample_label = data_loader.dataset[sample_index]\n",
        "    sample_image = sample_image.unsqueeze(0).to(device)\n",
        "    model_output = model(sample_image)\n",
        "    _, predicted_class = torch.max(model_output.data, 1)\n",
        "\n",
        "    # Inverse transform predicted and true labels for display\n",
        "    predicted_class = label_encoder.inverse_transform([predicted_class.item()])[0]\n",
        "    true_label = label_encoder.inverse_transform([sample_label.item()])[0]\n",
        "\n",
        "    print(f\"\\nSample Image:\")\n",
        "    imeshow(sample_image.cpu().squeeze())\n",
        "    print(f\"True Label: {true_label}\")\n",
        "    print(f\"Predicted Label: {predicted_class}\")\n",
        "\n",
        "def display_confusion_matrix(all_labels, all_predicted, label_encoder):\n",
        "    cm = confusion_matrix(all_labels, all_predicted)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_,\n",
        "                yticklabels=label_encoder.classes_)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.show()\n",
        "\n",
        "# Usage\n",
        "model.eval()\n",
        "all_labels = []\n",
        "all_predicted = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(test_dataloader):\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_predicted.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Evaluate classification metrics\n",
        "accuracy, precision, recall, f1, class_accuracies = evaluate_classification_metrics(all_labels, all_predicted)\n",
        "print(\"Overall Metrics:\")\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
        "print(\"\\nAccuracy for Each Class:\")\n",
        "for i, class_acc in enumerate(class_accuracies):\n",
        "    class_label = lb.inverse_transform([i])[0]\n",
        "    print(f\"{class_label}: {class_acc * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmOIdfWBcPTD"
      },
      "outputs": [],
      "source": [
        "# Display a sample image and its predicted class\n",
        "display_sample_image(model, test_dataloader, device, lb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOmAiIVEcRbG"
      },
      "outputs": [],
      "source": [
        "# Display confusion matrix\n",
        "display_confusion_matrix(all_labels, all_predicted, lb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5 Saving results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create folder with correct naming\n",
        "current_date = datetime.datetime.now().strftime(\"%d.%m.%Y_%H.%M.%S\")\n",
        "folder = f\"results/{current_date}_epoch={num_epochs}_f1acc={round(f1 * 100, 2)}%\"\n",
        "Path(folder).mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "print(f\"Folder created in: {folder}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.system(f'jupyter nbconvert --to html Eye_Disease_Detection.ipynb --output-dir={folder}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
